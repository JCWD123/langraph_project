import uuid
from dotenv import load_dotenv
from langchain_core.messages import AIMessage, HumanMessage
from graph.graph import create_graph, stream_graph_updates
from graph.state import plan_state
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib.colors import HexColor, blue, red, green, black, white
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from langchain_core.globals import set_debug
from datetime import datetime
import pandas as pd
import os
import sys
import re
from suppliers_config import DEFAULT_SUPPLIERS, QUERY_TEMPLATE

def register_chinese_font():
    """æ³¨å†Œä¸­æ–‡å­—ä½“"""
    try:
        # å°è¯•æ³¨å†Œç³»ç»Ÿä¸­çš„ä¸­æ–‡å­—ä½“
        font_paths = [
            '/System/Library/Fonts/STHeiti Light.ttc',  # macOS
            '/System/Library/Fonts/Helvetica.ttc'     # macOSå¤‡é€‰
        ]
        
        for font_path in font_paths:
            if os.path.exists(font_path):
                pdfmetrics.registerFont(TTFont('ChineseFont', font_path))
                return True
    except:
        pass
    return False

def clean_content(content):
    """å¢å¼ºç‰ˆå†…å®¹æ¸…æ´—ï¼Œå»é™¤è°ƒè¯•ä¿¡æ¯å’Œæ ¼å¼åŒ–é—®é¢˜"""
    if not isinstance(content, str):
        content = str(content)
    
    # å»é™¤stepsç­‰è°ƒè¯•ä¿¡æ¯
    content = re.sub(r'"steps":\s*\[.*?\]', '', content, flags=re.DOTALL)
    content = re.sub(r'\{[^}]*"steps"[^}]*\}', '', content, flags=re.DOTALL)
    content = re.sub(r'{"steps"[^}]*}', '', content, flags=re.DOTALL)
    
    # å»é™¤HTMLæ ‡ç­¾å’Œé“¾æ¥ç‰‡æ®µ  
    content = re.sub(r'<[^>]+>', '', content)
    content = re.sub(r'\[!\[Image \d+\].*?\]', '', content)
    # content = re.sub(r'https?://[^\s\]]+', '', content)
    
    # æ¸…ç†ä¹±ç å­—ç¬¦ï¼ˆUTF-8ç¼–ç é—®é¢˜å¯¼è‡´çš„ä¹±ç ï¼‰
    content = re.sub(r'[Ã¥ Â¬Ã¥Â¸Ã¦Â¥Ã¦Ã¥Â½Ã¥ Ã¤Â¸Ã¦ÂµÃ§Ã¥Â¶Ã© Ã¥ÂºÃ¥Â°Ã¤Â¸Ã§ Ã¥Ã¥Â¹Â³Ã¥Â°Ã¯Â¼Ã¤Â¸Ã¤Â¸Ã§Ã¦Ã¦Â¯Ã©Ã¤Â¼Ã¯Â¼Ã¥Â®Ã¥Ã§Ã¥Â·Â¥Ã§Â¨Ã©Â¡Â¹Ã§Â®Ã¥Ã¥Â¯Ã£Ã§Ã¥Ã£Ã¨Â®Â¾Ã¨Â®Â¡Ã£Ã¦Â½Ã¥Â·Â¥Ã£Ã¨Â°Ã¨Â¯Ã£Ã§Â»Â´Ã¦Â¤Ã§Â®Â¡Ã§Ã¤Â¸ÂºÃ¤Â¸Ã¤Â½Ã§Ã¦Â¶Ã¦Ã¤Â½Ã§Â³Â»Ã¯Â¼Ã¥Â»ÂºÃ¨Â®Â¾Ã¦Ã¥ Ã¦Â¬Ã¥Â¨Ã¦Ã¦Â¨Â¡Ã¦Ã¥Â®Ã©ÂªÃ¥Â°Ã¦Â¶Ã£Ã¥Ã§Â¦Â»Ã¦Â§Ã¨Â½Ã¦ÂµÃ¨Â¯Ã¥Â¹Â³Ã¥Â°Ã£Ã¥Ã¥Â¨Ã¦ÂºÃ¨Â¯Ã©ÂªÃ¥Â°Ã¦Â¶Ã¥Â¨Ã¥ Ã§Ã¥Ã¨Â¿Ã¥Â·Â¥Ã¨ÂºÃ¨Â®Â¾Ã¥Â¤Ã¯Â¼Ã© Ã§Â½Â®Ã¦Ã¥Â®Ã¥Ã§Ã¦Â£Ã¦ÂµÃ£Ã¥Ã¦Ã¤Â»ÂªÃ¥Â¨Ã¥FLUENTÃ£ASPENÃ£ANSYSÃ¤Â»Â¥Ã¥SOLIDWORKSÃ§Ã¥Ã¨Â¿Ã§Ã¥Ã¦Ã£Ã¦Â¨Â¡Ã¦Ã£Ã¤Â»Â¿Ã§Ã£Ã¤Â¸Ã§Â»Â´Ã¨Â®Â¾Ã¨Â®Â¡Ã¨Â½Â¯Ã¤Â»Â¶Ã¯Â¼Ã¥Â¹Â¶Ã¥Â¨Ã©Â¿Ã¦Ã§Ã§Ã¤ÂºÂ§Ã¥Â®Ã¨Â·ÂµÃ¤Â¸Ã¦Â»Ã§Â»Ã¥ÂºÃ¤ÂºÃ¤Â¸Ã¥Â¥Ã§Â§Ã¥]+', '', content)
    
    # æ¸…ç†å…¶ä»–ç±»å‹çš„ä¹±ç å’Œæ— æ„ä¹‰å­—ç¬¦
    content = re.sub(r'[+å…‹+å…+å…+å…‘+å…”+å…–+å…š+å…œ+å…¢+å…¥+å…¨+å…«+å…¬+å…­+å…®+å…°+å…±+å…³+å…´+å…µ+å…¶+å…·+å…¸+å…¹]+', '', content)
    content = re.sub(r'9\.78\d+E\+\d+', '', content)  # å»é™¤ç§‘å­¦è®¡æ•°æ³•çš„æ— æ„ä¹‰æ•°å­—
    content = re.sub(r'ISBN[\s\d\-]+', '', content)  # å»é™¤ISBNå·
    content = re.sub(r'\$\d+,\d+\.\d+', '', content)  # å»é™¤ç¾å…ƒé‡‘é¢
    
    # æ¸…ç†é”™è¯¯çš„å¼•ç”¨æ ¼å¼å’Œåˆ—è¡¨
    content = re.sub(r'\[".*?"\]', '', content, flags=re.DOTALL)
    content = re.sub(r'\[.*?\.\.\.\]', '', content, flags=re.DOTALL)
    
    # æ¸…ç†æ— æ ‡ç‚¹çš„é•¿æ–‡æœ¬ï¼ˆå¦‚"å­¦æŒ‡ä¸‰è±åŒ–å­¦æ ªå¼ä¼šç¤¾å¤©èµææ–™æŒ‡..."ï¼‰
    def fix_company_definitions(text):
        """ä¿®å¤å…¬å¸åç§°å®šä¹‰æ–‡æœ¬çš„æ ¼å¼"""
        # è¯†åˆ«"AæŒ‡Bå…¬å¸"çš„æ¨¡å¼å¹¶æ·»åŠ æ ‡ç‚¹
        text = re.sub(r'([^ã€‚ï¼Œï¼›,;.]\w+)æŒ‡([^æŒ‡]{10,}?)([æŒ‡])', r'\1æŒ‡\2ã€‚\3', text)
        text = re.sub(r'([^ã€‚ï¼Œï¼›,;.]\w+)æŒ‡([^æŒ‡ã€‚]{15,}?)([A-Z])', r'\1æŒ‡\2ã€‚\3', text)
        return text
    
    content = fix_company_definitions(content)
    
    # æ¸…ç†è¿‡é•¿çš„æ— æ ‡ç‚¹æ®µè½ï¼ˆè¶…è¿‡100å­—ç¬¦ä¸”æ— æ ‡ç‚¹ï¼‰
    lines = content.split('\n')
    cleaned_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ— æ ‡ç‚¹çš„è¶…é•¿æ–‡æœ¬
        if len(line) > 100:
            # è®¡ç®—æ ‡ç‚¹ç¬¦å·æ¯”ä¾‹
            punctuation_count = len(re.findall(r'[ã€‚ï¼Œï¼›,;.!?]', line))
            char_count = len(line)
            punctuation_ratio = punctuation_count / char_count if char_count > 0 else 0
            
            # å¦‚æœæ ‡ç‚¹ç¬¦å·æ¯”ä¾‹å°äº1%ï¼Œè®¤ä¸ºæ˜¯æ— æ„ä¹‰çš„é•¿æ–‡æœ¬
            if punctuation_ratio < 0.01:
                continue  # è·³è¿‡è¿™ç§æ— æ ‡ç‚¹çš„é•¿æ–‡æœ¬
                
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§é‡é‡å¤çš„è®¢å•ä¿¡æ¯
        if ('è®¢å•ç¼–å·' in line and len(line) > 200) or ('åˆåŒé‡‘é¢' in line and len(line) > 200):
            continue  # è·³è¿‡è¡¨æ ¼å¼çš„è®¢å•ä¿¡æ¯
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä¹±ç è¡Œï¼ˆåŒ…å«å¤§é‡ç‰¹æ®Šå­—ç¬¦ï¼‰
        special_char_count = len(re.findall(r'[Ã¯Â¼Ã£Ã¥Ã¦]', line))
        if special_char_count > len(line) * 0.3:  # å¦‚æœç‰¹æ®Šå­—ç¬¦è¶…è¿‡30%
            continue
            
        cleaned_lines.append(line)
    
    content = '\n'.join(cleaned_lines)
    
    # æ¸…ç†å¤šä½™çš„ç¬¦å·å’Œç©ºè¡Œ
    content = re.sub(r'\*\s*\*', '', content)
    content = re.sub(r'\.{3,}', '...', content)  # æ ‡å‡†åŒ–çœç•¥å·
    content = re.sub(r'\n\s*\n\s*\n+', '\n\n', content)  # åˆå¹¶å¤šä¸ªç©ºè¡Œ
    content = re.sub(r'^\s*[\*\-\+]\s*$', '', content, flags=re.MULTILINE)
    
    # æ™ºèƒ½æ·»åŠ æ®µè½åˆ†éš”
    content = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*([A-Z])', r'\1\n\2', content)  # ä¸­æ–‡å¥å·åè·Ÿè‹±æ–‡å­—æ¯çš„æ¢è¡Œ
    content = re.sub(r'([a-zA-Z])\s*([ï¼ˆä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', r'\1\n\2', content)  # è‹±æ–‡åè·Ÿä¸­æ–‡ç¼–å·çš„æ¢è¡Œ
    content = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*([ï¼ˆä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', r'\1\n\n\2', content)  # ä¸­æ–‡å¥å·åè·Ÿç¼–å·å¢åŠ ç©ºè¡Œ
    
    return content.strip()

def extract_references(content):
    """æå–å†…å®¹ä¸­çš„é“¾æ¥å¼•ç”¨"""
    if not isinstance(content, str):
        content = str(content)
        
    # æå–æ‰€æœ‰URLé“¾æ¥
    urls = re.findall(r'https?://[^\s\]]+', content)
    
    # å»é‡å¹¶æŒ‰åŸŸååˆ†ç±»
    unique_urls = list(set(urls))
    
    # ç®€å•çš„é‡è¦æ€§æ’åºï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
    priority_domains = ['official', 'gov', 'edu', 'org', 'com']
    sorted_urls = []
    
    for domain in priority_domains:
        domain_urls = [url for url in unique_urls if domain in url.lower()]
        sorted_urls.extend(domain_urls)
    
    # æ·»åŠ å‰©ä½™çš„URL
    remaining_urls = [url for url in unique_urls if url not in sorted_urls]
    sorted_urls.extend(remaining_urls)
    
    return sorted_urls[:10]  # æœ€å¤šä¿ç•™10ä¸ªé“¾æ¥

def create_enhanced_styles():
    """åˆ›å»ºå¢å¼ºçš„PDFæ ·å¼"""
    styles = getSampleStyleSheet()
    font_registered = register_chinese_font()
    font_name = 'ChineseFont' if font_registered else 'Helvetica'
    
    # æ ‡é¢˜æ ·å¼ï¼ˆåŠ ç²—+é¢œè‰²ï¼‰
    title_style = ParagraphStyle(
        'EnhancedTitle',
        parent=styles['Title'],
        fontName=font_name,
        fontSize=20,
        textColor=HexColor('#2E4057'),
        spaceAfter=24,
        spaceBefore=12,
        alignment=1,  # å±…ä¸­
    )
    
    # ä¸»æ ‡é¢˜æ ·å¼
    heading1_style = ParagraphStyle(
        'EnhancedHeading1',
        parent=styles['Heading1'],
        fontName=font_name,
        fontSize=16,
        textColor=HexColor('#1B4F72'),
        spaceAfter=12,
        spaceBefore=18,
        leftIndent=0,
    )
    
    # äºŒçº§æ ‡é¢˜æ ·å¼
    heading2_style = ParagraphStyle(
        'EnhancedHeading2',
        parent=styles['Heading2'],
        fontName=font_name,
        fontSize=14,
        textColor=HexColor('#2874A6'),
        spaceAfter=8,
        spaceBefore=12,
        leftIndent=12,
    )
    
    # ç¼–å·æ®µè½æ ·å¼
    numbered_style = ParagraphStyle(
        'NumberedSection',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=12,
        textColor=HexColor('#1B4F72'),
        spaceAfter=10,
        spaceBefore=10,
        leftIndent=0,
        firstLineIndent=0,
        leading=18,
    )
    
    # æ­£æ–‡æ ·å¼ï¼ˆé¦–è¡Œç¼©è¿›ï¼‰
    body_style = ParagraphStyle(
        'EnhancedBody',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=11,
        spaceAfter=6,
        spaceBefore=3,
        leftIndent=12,
        firstLineIndent=24,  # é¦–è¡Œç¼©è¿›
        leading=16,
    )
    
    # é«˜äº®æ¡†æ ·å¼
    highlight_style = ParagraphStyle(
        'HighlightBox',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=10,
        textColor=HexColor('#D35400'),
        backColor=HexColor('#FEF9E7'),
        borderColor=HexColor('#F39C12'),
        borderWidth=1,
        spaceAfter=6,
        spaceBefore=3,
        leftIndent=24,
        rightIndent=24,
        borderPadding=8,
    )
    
    # é“¾æ¥æ ·å¼
    link_style = ParagraphStyle(
        'LinkStyle',
        parent=styles['Normal'],
        fontName=font_name,
        fontSize=9,
        textColor=blue,
        spaceAfter=3,
        leftIndent=24,
    )
    
    return {
        'title': title_style,
        'heading1': heading1_style,
        'heading2': heading2_style,
        'body': body_style,
        'highlight': highlight_style,
        'link': link_style,
        'numbered': numbered_style
    }

def process_content_for_pdf(content):
    """å¤„ç†å†…å®¹ï¼Œè¯†åˆ«å¹¶æ ¼å¼åŒ–ä¸åŒç±»å‹çš„æ–‡æœ¬"""
    if not isinstance(content, str):
        content = str(content)
        
    lines = content.split('\n')
    processed_elements = []
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if not line:
            i += 1
            continue
            
        # è¯†åˆ«Markdownè¡¨æ ¼
        if '|' in line and line.count('|') >= 2:
            table_data, table_end_index = extract_table_from_lines(lines, i)
            if table_data:
                processed_elements.append(('table', table_data))
                i = table_end_index + 1
                continue
        
        # è¯†åˆ«ç¼–å·æ®µè½ï¼ˆä¸€ï¼‰ï¼ˆäºŒï¼‰ç­‰
        if re.match(r'^[ï¼ˆ(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d+][ï¼‰)]', line):
            processed_elements.append(('numbered', line))
            i += 1
            continue
            
        # è¯†åˆ«æ ‡é¢˜çº§åˆ«
        if line.startswith('## '):
            processed_elements.append(('heading1', line[3:]))
            i += 1
            continue
        elif line.startswith('### '):
            processed_elements.append(('heading2', line[4:]))
            i += 1
            continue
            
        # è¯†åˆ«åŠ ç²—é‡ç‚¹å†…å®¹
        if line.startswith('**') and line.endswith('**'):
            processed_elements.append(('highlight', line[2:-2]))
            i += 1
            continue
            
        # è¯†åˆ«åˆ—è¡¨é¡¹
        if line.startswith('- ') or line.startswith('* '):
            processed_elements.append(('body', f"â€¢ {line[2:]}"))
            i += 1
            continue
            
        # è¯†åˆ«åŒ…å«å…³é”®è¯çš„å†…å®¹è¿›è¡Œé«˜äº®
        highlight_keywords = ['é‡è¦', 'å…³é”®', 'æ ¸å¿ƒ', 'ä¸»è¦', 'æ•°æ®', 'æŠ€æœ¯å‚æ•°', 'æ€§èƒ½æŒ‡æ ‡', 'ä¸“åˆ©', 'åˆ›æ–°']
        if any(keyword in line for keyword in highlight_keywords):
            processed_elements.append(('highlight', line))
            i += 1
            continue
            
        # è¿‡æ»¤æ‰è¿‡çŸ­æˆ–æ— æ„ä¹‰çš„è¡Œ
        if len(line) < 3 or line.count('...') > len(line) // 4:
            i += 1
            continue
            
        # æ™®é€šæ­£æ–‡
        processed_elements.append(('body', line))
        i += 1
    
    return processed_elements

def extract_table_from_lines(lines, start_index):
    """ä»æ–‡æœ¬è¡Œä¸­æå–è¡¨æ ¼æ•°æ®"""
    table_data = []
    current_index = start_index
    
    # æŸ¥æ‰¾è¡¨æ ¼çš„å¼€å§‹å’Œç»“æŸ
    while current_index < len(lines):
        line = lines[current_index].strip()
        
        if not line:
            current_index += 1
            continue
            
        if '|' not in line or line.count('|') < 2:
            break
            
        # è·³è¿‡åˆ†éš”çº¿ï¼ˆå¦‚ |------|------|ï¼‰
        if re.match(r'^[\|\-\s]+$', line):
            current_index += 1
            continue
            
        # è§£æè¡¨æ ¼è¡Œ
        cells = [cell.strip() for cell in line.split('|')]
        # å»é™¤é¦–å°¾çš„ç©ºå•å…ƒæ ¼
        cells = [cell for cell in cells if cell]
        
        if len(cells) >= 2:  # è‡³å°‘è¦æœ‰2åˆ—æ‰ç®—æœ‰æ•ˆè¡¨æ ¼è¡Œ
            table_data.append(cells)
        
        current_index += 1
    
    # å¦‚æœæ‰¾åˆ°äº†æœ‰æ•ˆçš„è¡¨æ ¼æ•°æ®ï¼ˆè‡³å°‘2è¡Œï¼‰
    if len(table_data) >= 2:
        return table_data, current_index - 1
    else:
        return None, start_index

def create_pdf_table(table_data, styles):
    """åˆ›å»ºPDFè¡¨æ ¼"""
    from reportlab.platypus import Table, TableStyle
    from reportlab.lib.colors import HexColor, black, white
    
    if not table_data or len(table_data) == 0:
        return None
    
    # ç¡®ä¿æ‰€æœ‰è¡Œçš„åˆ—æ•°ä¸€è‡´
    max_cols = max(len(row) for row in table_data)
    normalized_data = []
    
    for row in table_data:
        normalized_row = row + [''] * (max_cols - len(row))
        normalized_data.append(normalized_row)
    
    # åˆ›å»ºè¡¨æ ¼
    table = Table(normalized_data)
    
    # è®¾ç½®è¡¨æ ¼æ ·å¼
    table_style = TableStyle([
        # è¡¨å¤´æ ·å¼
        ('BACKGROUND', (0, 0), (-1, 0), HexColor('#4A90E2')),
        ('TEXTCOLOR', (0, 0), (-1, 0), white),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'ChineseFont' if register_chinese_font() else 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 11),
        
        # è¡¨æ ¼å†…å®¹æ ·å¼
        ('BACKGROUND', (0, 1), (-1, -1), HexColor('#F8F9FA')),
        ('TEXTCOLOR', (0, 1), (-1, -1), black),
        ('FONTNAME', (0, 1), (-1, -1), 'ChineseFont' if register_chinese_font() else 'Helvetica'),
        ('FONTSIZE', (0, 1), (-1, -1), 10),
        
        # è¾¹æ¡†æ ·å¼
        ('GRID', (0, 0), (-1, -1), 1, HexColor('#CCCCCC')),
        ('LINEBELOW', (0, 0), (-1, 0), 2, HexColor('#4A90E2')),
        
        # è¡Œé—´è·
        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [HexColor('#F8F9FA'), white]),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ('LEFTPADDING', (0, 0), (-1, -1), 8),
        ('RIGHTPADDING', (0, 0), (-1, -1), 8),
        ('TOPPADDING', (0, 0), (-1, -1), 6),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 6),
    ])
    
    table.setStyle(table_style)
    
    return table

def create_single_supplier_pdf(supplier_data, filename):
    """ä¸ºå•ä¸ªä¾›åº”å•†åˆ›å»ºå¢å¼ºç‰ˆPDFæŠ¥å‘Š"""
    doc = SimpleDocTemplate(filename, pagesize=A4, topMargin=1*inch, bottomMargin=1*inch)
    styles = create_enhanced_styles()
    story = []
    
    supplier_name = supplier_data['supplier']
    query = supplier_data['query']
    response = supplier_data['response']
    
    # æ¸…æ´—å†…å®¹
    cleaned_response = clean_content(response)
    
    # æå–é“¾æ¥
    references = extract_references(response)
    
    # æ·»åŠ æŠ¥å‘Šæ ‡é¢˜
    story.append(Paragraph(f"{supplier_name} äº§å“ä¿¡æ¯æŠ¥å‘Š", styles['title']))
    story.append(Paragraph(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}", styles['body']))
    story.append(Spacer(1, 0.3*inch))
    
    # å¤„ç†å¹¶æ·»åŠ ä¸»è¦å†…å®¹
    content_elements = process_content_for_pdf(cleaned_response)
    
    for element_type, content in content_elements:
        if not content:
            continue
            
        try:
            if element_type == 'table':
                # å¤„ç†è¡¨æ ¼
                table = create_pdf_table(content, styles)
                if table:
                    story.append(Spacer(1, 0.1*inch))
                    story.append(table)
                    story.append(Spacer(1, 0.2*inch))
            else:
                # å¤„ç†æ™®é€šæ–‡æœ¬
                text = str(content)
                if text and text.strip():
                    story.append(Paragraph(text, styles[element_type]))
                    if element_type == 'heading1':
                        story.append(Spacer(1, 0.1*inch))
                    elif element_type == 'numbered':
                        story.append(Spacer(1, 0.08*inch))
                    elif element_type == 'highlight':
                        story.append(Spacer(1, 0.05*inch))
        except Exception as e:
            print(f"  âš ï¸ å¤„ç†å†…å®¹æ—¶å‡ºé”™: {e}, ç±»å‹: {element_type}, å†…å®¹: {str(content)[:50]}...")
            # ä½¿ç”¨é»˜è®¤æ ·å¼ä½œä¸ºå¤‡é€‰
            if element_type != 'table':
                try:
                    story.append(Paragraph(str(content), styles['body']))
                except:
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸€è¡Œ
                    continue
    
    # æ·»åŠ å‚è€ƒèµ„æ–™éƒ¨åˆ†
    if references:
        story.append(Spacer(1, 0.3*inch))
        story.append(Paragraph("å‚è€ƒèµ„æ–™æ¥æº", styles['heading1']))
        story.append(Spacer(1, 0.1*inch))
        
        for i, ref in enumerate(references, 1):
            story.append(Paragraph(f"{i}. {ref}", styles['link']))
    
    # æ„å»ºPDF
    doc.build(story)
    print(f"  â†’ å•ç‹¬PDFå·²ç”Ÿæˆ: {filename}")

def create_pdf_report(suppliers_data, filename="ä¾›åº”å•†äº§å“ä¿¡æ¯æŠ¥å‘Š.pdf"):
    """åˆ›å»ºå¢å¼ºç‰ˆåˆå¹¶PDFæŠ¥å‘Š"""
    doc = SimpleDocTemplate(filename, pagesize=A4, topMargin=1*inch, bottomMargin=1*inch)
    styles = create_enhanced_styles()
    story = []
    
    # æ·»åŠ æŠ¥å‘Šæ ‡é¢˜
    story.append(Paragraph("ä¾›åº”å•†äº§å“ä¿¡æ¯æŸ¥è¯¢æŠ¥å‘Šï¼ˆåˆå¹¶ç‰ˆï¼‰", styles['title']))
    story.append(Paragraph(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}", styles['body']))
    story.append(Paragraph(f"åŒ…å«ä¾›åº”å•†æ•°é‡: {len(suppliers_data)}", styles['body']))
    story.append(Spacer(1, 0.3*inch))
    
    # æ”¶é›†æ‰€æœ‰å¼•ç”¨é“¾æ¥
    all_references = []
    
    # ä¸ºæ¯ä¸ªä¾›åº”å•†æ·»åŠ å†…å®¹
    for i, supplier_data in enumerate(suppliers_data):
        if i > 0:  # é™¤äº†ç¬¬ä¸€ä¸ªä¾›åº”å•†å¤–ï¼Œéƒ½æ·»åŠ åˆ†é¡µç¬¦
            story.append(PageBreak())
        
        supplier_name = supplier_data['supplier']
        query = supplier_data['query']
        response = supplier_data['response']
        
        # æ¸…æ´—å†…å®¹å’Œæå–é“¾æ¥
        cleaned_response = clean_content(response)
        references = extract_references(response)
        all_references.extend(references)
        
        # ä¾›åº”å•†æ ‡é¢˜
        story.append(Paragraph(f"ä¾›åº”å•† {i+1}: {supplier_name}", styles['heading1']))
        story.append(Spacer(1, 0.2*inch))
        
        # å¤„ç†å¹¶æ·»åŠ ä¸»è¦å†…å®¹
        content_elements = process_content_for_pdf(cleaned_response)
        
        for element_type, content in content_elements:
            if not content:
                continue
                
            try:
                if element_type == 'table':
                    # å¤„ç†è¡¨æ ¼
                    table = create_pdf_table(content, styles)
                    if table:
                        story.append(Spacer(1, 0.1*inch))
                        story.append(table)
                        story.append(Spacer(1, 0.2*inch))
                else:
                    # å¤„ç†æ™®é€šæ–‡æœ¬
                    text = str(content)
                    if text and text.strip():
                        story.append(Paragraph(text, styles[element_type]))
                        if element_type == 'heading1':
                            story.append(Spacer(1, 0.1*inch))
                        elif element_type == 'numbered':
                            story.append(Spacer(1, 0.08*inch))
                        elif element_type == 'highlight':
                            story.append(Spacer(1, 0.05*inch))
            except Exception as e:
                print(f"  âš ï¸ å¤„ç†å†…å®¹æ—¶å‡ºé”™: {e}, ç±»å‹: {element_type}, å†…å®¹: {str(content)[:50]}...")
                # ä½¿ç”¨é»˜è®¤æ ·å¼ä½œä¸ºå¤‡é€‰
                if element_type != 'table':
                    try:
                        story.append(Paragraph(str(content), styles['body']))
                    except:
                        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸€è¡Œ
                        continue
        
        story.append(Spacer(1, 0.2*inch))
    
    # æ·»åŠ æ•´ä½“å‚è€ƒèµ„æ–™éƒ¨åˆ†
    if all_references:
        story.append(PageBreak())
        story.append(Paragraph("å‚è€ƒèµ„æ–™æ¥æºæ±‡æ€»", styles['heading1']))
        story.append(Spacer(1, 0.2*inch))
        
        # å»é‡å¹¶æ’åº
        unique_references = list(set(all_references))
        sorted_references = extract_references(' '.join(unique_references))
        
        for i, ref in enumerate(sorted_references, 1):
            story.append(Paragraph(f"{i}. {ref}", styles['link']))
    
    # æ„å»ºPDF
    doc.build(story)
    print(f"âœ“ åˆå¹¶PDFæŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    set_debug(True)  # å¯ç”¨langchainè°ƒè¯•æ¨¡å¼ï¼Œå¯ä»¥è·å¾—å¦‚å®Œæ•´æç¤ºè¯ç­‰ä¿¡æ¯
    load_dotenv(verbose=True)  # åŠ è½½ç¯å¢ƒå˜é‡é…ç½®
    
    # è¯»å–æ•°æ®è¡¨ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
    try:
        suppliers_df = pd.read_excel('ä¼ä¸šåç§°.xlsx')
        suppliers = [c for c in suppliers_df['ä¼ä¸šåç§°']]
        print("âœ“ ä»Excelæ–‡ä»¶è¯»å–ä¾›åº”å•†åˆ—è¡¨")
    except:
        # ä»é…ç½®æ–‡ä»¶è¯»å–ä¾›åº”å•†åˆ—è¡¨
        suppliers = DEFAULT_SUPPLIERS
        print("âœ“ ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤ä¾›åº”å•†åˆ—è¡¨")
    
    # ä¹Ÿå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šä¾›åº”å•†
    if len(sys.argv) > 1:
        # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨å‚æ•°ä½œä¸ºä¾›åº”å•†åˆ—è¡¨
        suppliers = sys.argv[1:]
        print(f"âœ“ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„ä¾›åº”å•†: {suppliers}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"ä¾›åº”å•†æŠ¥å‘Š_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    print(f"âœ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    
    # åˆ›å»ºçŠ¶æ€å›¾ä»¥åŠå¯¹è¯ç›¸å…³çš„è®¾ç½®
    config = {
        "configurable": {"thread_id": uuid.uuid4().hex},
        "recursion_limit": 100
    }
    graph = create_graph()
    
    all_suppliers_data = []  # å­˜å‚¨æ‰€æœ‰ä¾›åº”å•†çš„æ•°æ®
    
    print("\nå¼€å§‹è‡ªåŠ¨åŒ–æŸ¥è¯¢ä¾›åº”å•†äº§å“ä¿¡æ¯...")
    print(f"è®¡åˆ’æŸ¥è¯¢ {len(suppliers)} ä¸ªä¾›åº”å•†")
    print("=" * 50)
    
    # å¾ªç¯å¤„ç†æ¯ä¸ªä¾›åº”å•†
    for i, supplier in enumerate(suppliers, 1):
        print(f"\næ­£åœ¨æŸ¥è¯¢ç¬¬ {i}/{len(suppliers)} ä¸ªä¾›åº”å•†: {supplier}")
        print("-" * 30)
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æŸ¥è¯¢æ¨¡æ¿åŠ¨æ€ç”ŸæˆæŸ¥è¯¢å†…å®¹
        query = QUERY_TEMPLATE.format(supplier=supplier)
        print(f"æŸ¥è¯¢å†…å®¹: {query}")
        
        # åˆ›å»ºæ–°çš„çŠ¶æ€ï¼ˆæ¯ä¸ªä¾›åº”å•†ä½¿ç”¨ç‹¬ç«‹çš„çŠ¶æ€ï¼‰
        state = plan_state(
            task=query,
            goal='',
            messages=[],
            steps=[],
            steps2results={},
            documents=[]
        )
        
        # æ¸…æ´—è¾“å…¥ï¼Œå»é™¤éæ³•Unicodeå­—ç¬¦
        query_clean = query.encode('utf-8', 'ignore').decode('utf-8')
        state["messages"].append(HumanMessage(content=query_clean))
        state["task"] = query_clean
        
        ai_response = ""  # ç”¨äºæ”¶é›†AIå›å¤
        
        print("AIå›å¤:")
        # æµå¼è·å–AIçš„å›å¤
        try:
            for answer in stream_graph_updates(graph, state, config):
                print(answer, end="")
                # ç¡®ä¿answerä¸ºstrç±»å‹
                if isinstance(answer, list):
                    answer = "".join(str(x) for x in answer)
                ai_response += str(answer)
        except Exception as e:
            print(f"æŸ¥è¯¢ {supplier} æ—¶å‡ºé”™: {e}")
            ai_response = f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
        
        print()  # æ¢è¡Œ
        
        # ä¿å­˜æœ¬è½®æŸ¥è¯¢ç»“æœ
        supplier_data = {
            "supplier": supplier,
            "query": query,
            "response": ai_response
        }
        all_suppliers_data.append(supplier_data)
        
        # æ¸è¿›å¼ä¿å­˜ï¼šç«‹å³ä¸ºå½“å‰ä¾›åº”å•†ç”Ÿæˆå•ç‹¬çš„PDF
        try:
            single_pdf_filename = os.path.join(output_dir, f"{supplier}äº§å“ä¿¡æ¯æŠ¥å‘Š_{timestamp}.pdf")
            create_single_supplier_pdf(supplier_data, single_pdf_filename)
        except Exception as e:
            print(f"  âš ï¸ ç”Ÿæˆ {supplier} å•ç‹¬PDFæ—¶å‡ºé”™: {e}")
            # å¤‡é€‰æ–¹æ¡ˆï¼šä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶
            txt_filename = os.path.join(output_dir, f"{supplier}äº§å“ä¿¡æ¯æŠ¥å‘Š_{timestamp}.txt")
            with open(txt_filename, "w", encoding="utf-8") as f:
                f.write(f"{supplier} äº§å“ä¿¡æ¯æŠ¥å‘Š\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"æŸ¥è¯¢å†…å®¹: {query}\n\n")
                f.write("è¯¦ç»†ä¿¡æ¯:\n")
                f.write(ai_response)
            print(f"  â†’ å¤‡é€‰æ–‡æœ¬æ–‡ä»¶å·²ç”Ÿæˆ: {txt_filename}")
        
        print(f"âœ“ {supplier} æŸ¥è¯¢å®Œæˆå¹¶å·²ä¿å­˜")
    
    print("\n" + "=" * 50)
    print("æ‰€æœ‰ä¾›åº”å•†æŸ¥è¯¢å®Œæˆ!")
    print(f"å•ç‹¬æŠ¥å‘Šæ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
    
    # ç”Ÿæˆåˆå¹¶çš„PDFæŠ¥å‘Š
    merged_pdf_filename = os.path.join(output_dir, f"åˆå¹¶_ä¾›åº”å•†äº§å“ä¿¡æ¯æŠ¥å‘Š_{timestamp}.pdf")
    
    try:
        create_pdf_report(all_suppliers_data, merged_pdf_filename)
    except Exception as e:
        print(f"ç”Ÿæˆåˆå¹¶PDFæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
        print("æ­£åœ¨ä¿å­˜ä¸ºæ–‡æœ¬æ ¼å¼ä½œä¸ºå¤‡é€‰...")
        
        # å¤‡é€‰æ–¹æ¡ˆï¼šä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶
        txt_filename = os.path.join(output_dir, f"åˆå¹¶_ä¾›åº”å•†äº§å“ä¿¡æ¯æŠ¥å‘Š_{timestamp}.txt")
        with open(txt_filename, "w", encoding="utf-8") as f:
            f.write("ä¾›åº”å•†äº§å“ä¿¡æ¯æŸ¥è¯¢æŠ¥å‘Šï¼ˆåˆå¹¶ç‰ˆï¼‰\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"åŒ…å«ä¾›åº”å•†æ•°é‡: {len(all_suppliers_data)}\n")
            f.write("=" * 50 + "\n\n")
            
            for i, supplier_data in enumerate(all_suppliers_data, 1):
                f.write(f"ä¾›åº”å•† {i}: {supplier_data['supplier']}\n")
                f.write(f"æŸ¥è¯¢å†…å®¹: {supplier_data['query']}\n")
                f.write("è¯¦ç»†ä¿¡æ¯:\n")
                f.write(supplier_data['response'])
                f.write("\n" + "-" * 50 + "\n\n")
        
        print(f"âœ“ åˆå¹¶æ–‡æœ¬æŠ¥å‘Šå·²ç”Ÿæˆ: {txt_filename}")
    
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“„ å•ç‹¬æŠ¥å‘Š: {len(suppliers)} ä¸ª")
    print(f"ğŸ“‹ åˆå¹¶æŠ¥å‘Š: 1 ä¸ª")

if __name__ == "__main__":
    main()
